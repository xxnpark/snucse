{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "(full_dim, mid_dim, hidden) = (1 * 28 * 28, 1000, 5)\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# STEP 1: Define dataset and preprocessing #\n",
    "############################################\n",
    "\n",
    "#####################################\n",
    "# STEP 2: Define prior distribution #\n",
    "#####################################\n",
    "\n",
    "class Logistic(torch.distributions.Distribution):\n",
    "    def __init__(self):\n",
    "        super(Logistic, self).__init__()\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        return -(F.softplus(x) + F.softplus(-x))\n",
    "\n",
    "    def sample(self, size):\n",
    "        z = torch.distributions.Uniform(0., 1.).sample(size).to(device)\n",
    "        return torch.log(z) - torch.log(1. - z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# STEP 3: Implement Coupling Layer #\n",
    "####################################\n",
    "\n",
    "class Coupling(nn.Module):\n",
    "    def __init__(self, in_out_dim, mid_dim, hidden, mask_config):\n",
    "        super(Coupling, self).__init__()\n",
    "        self.mask_config = mask_config\n",
    "        \n",
    "        self.in_block = nn.Sequential(nn.Linear(in_out_dim//2, mid_dim), nn.ReLU())\n",
    "        self.mid_block = nn.ModuleList([nn.Sequential(nn.Linear(mid_dim, mid_dim), nn.ReLU())\n",
    "                                                                 for _ in range(hidden - 1)])\n",
    "        self.out_block = nn.Linear(mid_dim, in_out_dim//2)\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        [B, W] = list(x.size())\n",
    "        x = x.reshape((B, W//2, 2))\n",
    "        if self.mask_config:\n",
    "            on, off = x[:, :, 0], x[:, :, 1]\n",
    "        else:\n",
    "            off, on = x[:, :, 0], x[:, :, 1]\n",
    "\n",
    "        off_ = self.in_block(off)\n",
    "        for i in range(len(self.mid_block)):\n",
    "            off_ = self.mid_block[i](off_)\n",
    "        shift = self.out_block(off_)\n",
    "        \n",
    "        if reverse:\n",
    "            on = on - shift\n",
    "        else:\n",
    "            on = on + shift\n",
    "\n",
    "        if self.mask_config:\n",
    "            x = torch.stack((on, off), dim=2)\n",
    "        else:\n",
    "            x = torch.stack((off, on), dim=2)\n",
    "        return x.reshape((B, W))\n",
    "\n",
    "class Scaling(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Scaling, self).__init__()\n",
    "        self.scale = nn.Parameter(torch.zeros((1, dim)), requires_grad=True)\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        log_det_J = torch.sum(self.scale)\n",
    "        if reverse:\n",
    "            x = x * torch.exp(-self.scale)\n",
    "        else:\n",
    "            x = x * torch.exp(self.scale)\n",
    "        return x, log_det_J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# STEP 4: Implement NICE #\n",
    "##########################\n",
    "\n",
    "class NICE(nn.Module):\n",
    "    def __init__(self,in_out_dim, mid_dim, hidden, mask_config=1.0, coupling=4):\n",
    "        super(NICE, self).__init__()\n",
    "        self.prior = Logistic()\n",
    "        self.in_out_dim = in_out_dim\n",
    "\n",
    "        self.coupling = nn.ModuleList([\n",
    "            Coupling(in_out_dim=in_out_dim, \n",
    "                     mid_dim=mid_dim, \n",
    "                     hidden=hidden, \n",
    "                     mask_config=(mask_config+i)%2) \\\n",
    "            for i in range(coupling)])\n",
    "        \n",
    "        self.scaling = Scaling(in_out_dim)\n",
    "\n",
    "    def g(self, z):\n",
    "        x, _ = self.scaling(z, reverse=True)\n",
    "        for i in reversed(range(len(self.coupling))):\n",
    "            x = self.coupling[i](x, reverse=True)\n",
    "        return x\n",
    "\n",
    "    def f(self, x):\n",
    "        for i in range(len(self.coupling)):\n",
    "            x = self.coupling[i](x)\n",
    "        z, log_det_J = self.scaling(x)\n",
    "        return z, log_det_J\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        z, log_det_J = self.f(x)\n",
    "        log_ll = torch.sum(self.prior.log_prob(z), dim=1)\n",
    "        return log_ll + log_det_J\n",
    "\n",
    "    def sample(self, size):\n",
    "        z = self.prior.sample((size, self.in_out_dim)).to(device)\n",
    "        return self.g(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.log_prob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/distributions/distribution.py:44: UserWarning: <class '__main__.Logistic'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load pre-trained NICE model onto CPU\n",
    "model = NICE(in_out_dim=784, mid_dim=1000, hidden=5).to(device)\n",
    "model.load_state_dict(torch.load('nice.pt',map_location=torch.device('cpu')))\n",
    "\n",
    "# Since we do not update model, set requires_grad = False\n",
    "model.requires_grad_(False)\n",
    "\n",
    "# Get an MNIST image\n",
    "testset = torchvision.datasets.MNIST(root='./', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n",
    "pass_count = 6\n",
    "itr = iter(test_loader)\n",
    "for _ in range(pass_count+1):\n",
    "    image,_ = itr.next()\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "ax1.set_title('Original Image')\n",
    "ax1.imshow(make_grid(image.squeeze().detach()).permute(1,2,0))\n",
    "# ax1.savefig('plt1.png')\n",
    "\n",
    "# Create mask \n",
    "mask = torch.ones_like(image,dtype=torch.bool)\n",
    "mask[:,:,5:12,5:20] = 0\n",
    "\n",
    "# Partially corrupt the image\n",
    "image[mask.logical_not()] = torch.ones_like(image[mask.logical_not()])\n",
    "ax2.set_title('Corrupted Image')\n",
    "ax2.imshow(make_grid(image.squeeze()).permute(1,2,0))\n",
    "# ax2.savefig('plt2.png')\n",
    "\n",
    "# Plot reconstruction\n",
    "X = image.clone().requires_grad_(True)\n",
    "for i in range(300):\n",
    "    X.data = X.data.view(-1, 28*28)\n",
    "    loss = -model(X)\n",
    "    loss.backward()\n",
    "    X.data = torch.clamp(X.data - lr * X.grad, min=0, max=1)\n",
    "    X.data[mask.view(-1, 28*28).logical_not().logical_not()] = image.view(-1, 28*28)[mask.view(-1, 28*28).logical_not().logical_not()]\n",
    "X.data = X.data.view(image.size())\n",
    "\n",
    "ax3.set_title('Reconstruction')\n",
    "ax3.imshow(make_grid(X.squeeze().detach()).permute(1,2,0))\n",
    "# ax3.savefig('plt3.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 0.000002 ± 0.000000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "N = 3000\n",
    "p = 18. / 37.\n",
    "q = 0.55\n",
    "max_play = 600\n",
    "\n",
    "def f(X_i):\n",
    "    return p**X_i * (1-p)**(1-X_i)\n",
    "\n",
    "def g(Y_i):\n",
    "    return q**Y_i * (1-q)**(1-Y_i)\n",
    "\n",
    "samp = []\n",
    "for _ in range(N):\n",
    "    Y = torch.bernoulli(q * torch.ones(max_play))\n",
    "    balance = 100\n",
    "    s = 1\n",
    "    for i in range(max_play):\n",
    "        balance += 2*Y[i]-1\n",
    "        s *= f(Y[i]) / g(Y[i])\n",
    "        if balance == 0 or balance == 200:\n",
    "            break\n",
    "    s *= (balance == 200).float()\n",
    "    samp.append(s)\n",
    "\n",
    "samp = torch.Tensor(samp)\n",
    "Ihat,s = samp.mean(), samp.var()\n",
    "print(f\"Estimate: {Ihat:.6f} ± {math.sqrt(s/N):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu = 0.3323487937450409\n",
      "sigma = 0.8285127878189087\n",
      "tensor([7.1168])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "lr = 1e-3\n",
    "B = 16\n",
    "iterations = 500\n",
    "mu = torch.tensor([0.])\n",
    "tau = torch.tensor([0.])\n",
    "\n",
    "for itr in range(iterations):\n",
    "    X = torch.normal(0, 1, size=(B,)) * tau.exp() + mu\n",
    "    mu -= lr * (torch.sum(X * X.sin() * (X - mu) / tau.exp()**2) / B + mu - 1)\n",
    "    tau -= lr * (torch.sum(X * X.sin() * ((X - mu)**2 / tau.exp() - 1)) / B + tau.exp() - 1)\n",
    "\n",
    "print(f\"mu = {mu[0]}\")\n",
    "print(f\"sigma = {tau.exp()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu = 0.3241511881351471\n",
      "sigma = 0.7526840567588806\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "lr = 1e-3\n",
    "B = 16\n",
    "iterations = 500\n",
    "mu = torch.tensor([0.])\n",
    "tau = torch.tensor([0.])\n",
    "\n",
    "for itr in range(iterations):\n",
    "    Y = torch.normal(0, 1, size=(B,))\n",
    "    X = mu + tau.exp() * Y\n",
    "    mu -= lr * (torch.sum(X.sin() + X * X.cos()) / B + mu - 1)\n",
    "    tau -= lr * (torch.sum((X.sin() + X * X.cos()) * Y) / B + tau.exp() - 1)\n",
    "    \n",
    "print(f\"mu = {mu[0]}\")\n",
    "print(f\"sigma = {tau.exp()[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
