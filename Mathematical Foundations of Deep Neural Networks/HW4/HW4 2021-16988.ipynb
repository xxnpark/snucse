{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZ-hYHqDeUuq"
   },
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWUzoaB_eUur",
    "outputId": "58b3d317-10c2-4e1a-e179-b61b5799e13c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KItoRM32eUus"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Step 1: Prepare dataset\n",
    "'''\n",
    "# Use data with only 4 and 9 as labels: which is hardest to classify\n",
    "label_1, label_2 = 4, 9\n",
    "\n",
    "# MNIST training data\n",
    "train_set = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# Use data with two labels\n",
    "idx = (train_set.targets == label_1) + (train_set.targets == label_2)\n",
    "train_set.data = train_set.data[idx]\n",
    "train_set.targets = train_set.targets[idx]\n",
    "train_set.targets[train_set.targets == label_1] = -1\n",
    "train_set.targets[train_set.targets == label_2] = 1\n",
    "\n",
    "# MNIST testing data\n",
    "test_set = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# Use data with two labels\n",
    "idx = (test_set.targets == label_1) + (test_set.targets == label_2)\n",
    "test_set.data = test_set.data[idx]\n",
    "test_set.targets = test_set.targets[idx]\n",
    "test_set.targets[test_set.targets == label_1] = -1\n",
    "test_set.targets[test_set.targets == label_2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dyRXo5ABeUus"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Step 2: Define the neural network class\n",
    "'''\n",
    "class LR(nn.Module) :\n",
    "    '''\n",
    "    Initialize model\n",
    "        input_dim : dimension of given input data\n",
    "    '''\n",
    "    # MNIST data is 28x28 images\n",
    "    def __init__(self, input_dim=28*28) :\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1, bias=False)\n",
    "\n",
    "    ''' forward given input x '''\n",
    "    def forward(self, x) :\n",
    "        return self.linear(x.float().view(-1, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "I-oC4bsKeUus"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Step 3: Create the model, specify loss function and optimizer.\n",
    "'''\n",
    "model = LR().to(device)\n",
    "\n",
    "def sum_of_squares_loss(output, target):\n",
    "    return 1/2 * (1 - target) * ((1 - torch.sigmoid(-output))**2 + (torch.sigmoid(output))**2) + 1/2 * (1 + target) * ((torch.sigmoid(-output))**2 + (1 - torch.sigmoid(output))**2)\n",
    "\n",
    "loss_function = sum_of_squares_loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=255*1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7svCZiD4eUus",
    "outputId": "1291eb84-17d7-4141-b1bc-c7a2215c4423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time ellapsed in training is: 18.5042941570282\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 4: Train model with SGD\n",
    "'''\n",
    "\n",
    "# shuffled cyclic SGD\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=1, shuffle=True)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "# Train the model (single epoch)\n",
    "for image, label in train_loader :\n",
    "    image, label = image.to(device), label.to(device)\n",
    "\n",
    "    # Clear previously computed gradient\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # then compute gradient with forward and backward passes\n",
    "    train_loss = loss_function(model(image), label.float())\n",
    "    train_loss.backward()\n",
    "\n",
    "    # perform SGD step (parameter update)\n",
    "    optimizer.step()    \n",
    "end = time.time()\n",
    "print(f\"Time ellapsed in training is: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AfXODzXveUut",
    "outputId": "402d5756-36a0-492b-b31f-64502421faee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test set] Average loss: 0.0548, Accuracy: 1927/1991 (96.79%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 5: Test model (Evaluate the accuracy)\n",
    "'''\n",
    "test_loss, correct = 0, 0\n",
    "misclassified_ind = []\n",
    "correct_ind = []\n",
    "\n",
    "# Test data\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=1, shuffle=False)\n",
    "# no need to shuffle test data\n",
    "\n",
    "# Evaluate accuracy using test data\n",
    "for ind, (image, label) in enumerate(test_loader) :\n",
    "    image, label = image.to(device), label.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(image)\n",
    "\n",
    "    # Calculate cumulative loss\n",
    "    test_loss += loss_function(output, label.float()).item()\n",
    "\n",
    "    # Make a prediction\n",
    "    if output.item() * label.item() >= 0 : \n",
    "        correct += 1\n",
    "        correct_ind += [ind]\n",
    "    else:\n",
    "        misclassified_ind += [ind]\n",
    "\n",
    "# Print out the results\n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss /len(test_loader), correct, len(test_loader),\n",
    "        100. * correct / len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdHirBBWeUut"
   },
   "source": [
    "Now repeat steps 3 ~ 5 using KL-divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "V1pi2WWIeUut"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Step 3: Create the model, specify loss function and optimizer.\n",
    "'''\n",
    "model = LR().to(device)\n",
    "\n",
    "def logistic_loss(output, target):\n",
    "    return -torch.nn.functional.logsigmoid(target*output)\n",
    "\n",
    "loss_function = logistic_loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=255*1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6SnP5OIUeUuu",
    "outputId": "896adcf2-2f54-472a-b9b3-ab5cbf29c0bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time ellapsed in training is: 9.621317386627197\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 4: Train model with SGD\n",
    "'''\n",
    "\n",
    "# shuffled cyclic SGD\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=1, shuffle=True)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "# Train the model (single epoch)\n",
    "for image, label in train_loader :\n",
    "    image, label = image.to(device), label.to(device)\n",
    "\n",
    "    # Clear previously computed gradient\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # then compute gradient with forward and backward passes\n",
    "    train_loss = loss_function(model(image), label.float())\n",
    "    train_loss.backward()\n",
    "\n",
    "    # perform SGD step (parameter update)\n",
    "    optimizer.step()    \n",
    "end = time.time()\n",
    "print(f\"Time ellapsed in training is: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R03Nh59LeUuu",
    "outputId": "b50a49cf-12fb-406b-842c-0414b4325ff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test set] Average loss: 0.0935, Accuracy: 1928/1991 (96.84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 5: Test model (Evaluate the accuracy)\n",
    "'''\n",
    "test_loss, correct = 0, 0\n",
    "misclassified_ind = []\n",
    "correct_ind = []\n",
    "\n",
    "# Test data\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=1, shuffle=False)\n",
    "# no need to shuffle test data\n",
    "\n",
    "# Evaluate accuracy using test data\n",
    "for ind, (image, label) in enumerate(test_loader) :\n",
    "    image, label = image.to(device), label.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(image)\n",
    "\n",
    "    # Calculate cumulative loss\n",
    "    test_loss += loss_function(output, label.float()).item()\n",
    "\n",
    "    # Make a prediction\n",
    "    if output.item() * label.item() >= 0 : \n",
    "        correct += 1\n",
    "        correct_ind += [ind]\n",
    "    else:\n",
    "        misclassified_ind += [ind]\n",
    "\n",
    "# Print out the results\n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss /len(test_loader), correct, len(test_loader),\n",
    "        100. * correct / len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RflzM9TLeUuu"
   },
   "source": [
    "Overall, using the two were similar in accuracy, but KL divergence showed better performance in terms of training time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mki2isHpeUuu"
   },
   "source": [
    "# Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jRF_9eCweUuu",
    "outputId": "86cff1ad-9b14-49d3-c940-d54105e5769d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jiKL8jQEeUuu"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Step 1\n",
    "'''\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gHH0QtsSeUuu"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Step 2: LeNet5\n",
    "'''\n",
    "\n",
    "# Modern LeNet uses this layer for C3\n",
    "class C3_layer_full(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C3_layer_full, self).__init__()\n",
    "        self.conv_layer = nn.Conv2d(6, 16, kernel_size=5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_layer(x)\n",
    "\n",
    "# Original LeNet uses this layer for C3\n",
    "class C3_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C3_layer, self).__init__()\n",
    "        self.ch_in_3 = [[0, 1, 2],\n",
    "                        [1, 2, 3],\n",
    "                        [2, 3, 4],\n",
    "                        [3, 4, 5],\n",
    "                        [0, 4, 5],\n",
    "                        [0, 1, 5]] # filter with 3 subset of input channels\n",
    "        self.ch_in_4 = [[0, 1, 2, 3],\n",
    "                        [1, 2, 3, 4],\n",
    "                        [2, 3, 4, 5],\n",
    "                        [0, 3, 4, 5],\n",
    "                        [0, 1, 4, 5],\n",
    "                        [0, 1, 2, 5],\n",
    "                        [0, 1, 3, 4],\n",
    "                        [1, 2, 4, 5],\n",
    "                        [0, 2, 3, 5]] # filter with 4 subset of input channels\n",
    "        # put implementation here\n",
    "        self.ch_3_layers = nn.ModuleList([nn.Conv2d(3, 1, kernel_size=5) for _ in range (6)])\n",
    "        self.ch_4_layers = nn.ModuleList([nn.Conv2d(4, 1, kernel_size=5) for _ in range (9)])\n",
    "        self.ch_6_layer = nn.Conv2d(6, 1, kernel_size=5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ch_outputs = []\n",
    "        ch_outputs += [self.ch_3_layers[i](x[:, self.ch_in_3[i], :, :]) for i in range(6)]\n",
    "        ch_outputs += [self.ch_4_layers[i](x[:, self.ch_in_4[i], :, :]) for i in range(9)]\n",
    "        ch_outputs += [self.ch_6_layer(x)]\n",
    "        return torch.cat(ch_outputs, dim=1)\n",
    "    \n",
    "class LeNet(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(LeNet, self).__init__()\n",
    "        # padding=2 makes 28x28 image into 32x32\n",
    "        self.C1_layer = nn.Sequential(\n",
    "                nn.Conv2d(1, 6, kernel_size=5, padding=2),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.P2_layer = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.C3_layer = nn.Sequential(\n",
    "                # C3_layer_full(),\n",
    "                C3_layer(),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.P4_layer = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.C5_layer = nn.Sequential(\n",
    "                nn.Linear(5*5*16, 120),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.F6_layer = nn.Sequential(\n",
    "                nn.Linear(120, 84),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.F7_layer = nn.Linear(84, 10)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        output = self.C1_layer(x)\n",
    "        output = self.P2_layer(output)\n",
    "        output = self.C3_layer(output)\n",
    "        output = self.P4_layer(output)\n",
    "        output = output.view(-1,5*5*16)\n",
    "        output = self.C5_layer(output)\n",
    "        output = self.F6_layer(output)\n",
    "        output = self.F7_layer(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Mhp3syyeUuu",
    "outputId": "6406fffd-a859-43d1-9ea9-44e711ca2544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters: 60806\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 3\n",
    "'''\n",
    "model = LeNet().to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
    "\n",
    "# print total number of trainable parameters\n",
    "param_ct = sum([p.numel() for p in model.parameters()])\n",
    "print(f\"Total number of trainable parameters: {param_ct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1XcBuVSeUuv",
    "outputId": "b5deaea8-81bc-469c-986e-d265bcd7fdf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th epoch starting.\n",
      "1th epoch starting.\n",
      "2th epoch starting.\n",
      "3th epoch starting.\n",
      "4th epoch starting.\n",
      "5th epoch starting.\n",
      "6th epoch starting.\n",
      "7th epoch starting.\n",
      "8th epoch starting.\n",
      "9th epoch starting.\n",
      "Time ellapsed in training is: 97.80957221984863\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 4\n",
    "'''\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(10) :\n",
    "    print(\"{}th epoch starting.\".format(epoch))\n",
    "    for images, labels in train_loader :\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss = loss_function(model(images), labels)\n",
    "        train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "end = time.time()\n",
    "print(\"Time ellapsed in training is: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nlc9TvYHeUuv",
    "outputId": "aeacd06d-ae94-4f02-9442-a73581083db7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test set] Average loss: 0.0005, Accuracy: 9826/10000 (98.26%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 5\n",
    "'''\n",
    "test_loss, correct, total = 0, 0, 0\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "for images, labels in test_loader :\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    output = model(images)\n",
    "    test_loss += loss_function(output, labels).item()\n",
    "\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    \n",
    "    total += labels.size(0)\n",
    "            \n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss /total, correct, total,\n",
    "        100. * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBE0IRbBnm3l"
   },
   "source": [
    "Now try steps 2 ~ 4 with the regular conv2d layer for C3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iLErdeoXm91p",
    "outputId": "ad0cba99-1795-4029-e568-ae4fda5d87a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters: 61706\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 2: LeNet5\n",
    "'''\n",
    "\n",
    "# Modern LeNet uses this layer for C3\n",
    "class C3_layer_full(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C3_layer_full, self).__init__()\n",
    "        self.conv_layer = nn.Conv2d(6, 16, kernel_size=5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_layer(x)\n",
    "\n",
    "# Original LeNet uses this layer for C3\n",
    "class C3_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C3_layer, self).__init__()\n",
    "        self.ch_in_3 = [[0, 1, 2],\n",
    "                        [1, 2, 3],\n",
    "                        [2, 3, 4],\n",
    "                        [3, 4, 5],\n",
    "                        [0, 4, 5],\n",
    "                        [0, 1, 5]] # filter with 3 subset of input channels\n",
    "        self.ch_in_4 = [[0, 1, 2, 3],\n",
    "                        [1, 2, 3, 4],\n",
    "                        [2, 3, 4, 5],\n",
    "                        [0, 3, 4, 5],\n",
    "                        [0, 1, 4, 5],\n",
    "                        [0, 1, 2, 5],\n",
    "                        [0, 1, 3, 4],\n",
    "                        [1, 2, 4, 5],\n",
    "                        [0, 2, 3, 5]] # filter with 4 subset of input channels\n",
    "        # put implementation here\n",
    "        self.ch_3_layers = nn.ModuleList([nn.Conv2d(3, 1, kernel_size=5) for _ in range (6)])\n",
    "        self.ch_4_layers = nn.ModuleList([nn.Conv2d(4, 1, kernel_size=5) for _ in range (9)])\n",
    "        self.ch_6_layer = nn.Conv2d(6, 1, kernel_size=5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ch_outputs = []\n",
    "        ch_outputs += [self.ch_3_layers[i](x[:, self.ch_in_3[i], :, :]) for i in range(6)]\n",
    "        ch_outputs += [self.ch_4_layers[i](x[:, self.ch_in_4[i], :, :]) for i in range(9)]\n",
    "        ch_outputs += [self.ch_6_layer(x)]\n",
    "        return torch.cat(ch_outputs, dim=1)\n",
    "    \n",
    "class LeNet(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(LeNet, self).__init__()\n",
    "        # padding=2 makes 28x28 image into 32x32\n",
    "        self.C1_layer = nn.Sequential(\n",
    "                nn.Conv2d(1, 6, kernel_size=5, padding=2),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.P2_layer = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.C3_layer = nn.Sequential(\n",
    "                C3_layer_full(),\n",
    "                # C3_layer(),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.P4_layer = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.C5_layer = nn.Sequential(\n",
    "                nn.Linear(5*5*16, 120),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.F6_layer = nn.Sequential(\n",
    "                nn.Linear(120, 84),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.F7_layer = nn.Linear(84, 10)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        output = self.C1_layer(x)\n",
    "        output = self.P2_layer(output)\n",
    "        output = self.C3_layer(output)\n",
    "        output = self.P4_layer(output)\n",
    "        output = output.view(-1,5*5*16)\n",
    "        output = self.C5_layer(output)\n",
    "        output = self.F6_layer(output)\n",
    "        output = self.F7_layer(output)\n",
    "        return output\n",
    "\n",
    "'''\n",
    "Step 3\n",
    "'''\n",
    "model = LeNet().to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
    "\n",
    "# print total number of trainable parameters\n",
    "param_ct = sum([p.numel() for p in model.parameters()])\n",
    "print(f\"Total number of trainable parameters: {param_ct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgW2J4DBnu33"
   },
   "source": [
    "We can see that a total of 900 parameters are reduced.\n",
    "This can be calculated as\n",
    "$$6 \\times (1 \\times 5 \\times 5 + 1) + 6 \\times (3 \\times 5 \\times 5 + 1) + 9 \\times (4 \\times 5 \\times 5 + 1) + 1 \\times (6 \\times 5 \\times 5 + 1) + 120 \\times (16 \\times 5 \\times 5 + 1) + 84 \\times (120 + 1) + 10 \\times (84 + 1) = 60806$$\n",
    "for the original C3 model and \n",
    "$$6 \\times (1 \\times 5 \\times 5 + 1) + 16 \\times (6 \\times 5 \\times 5 + 1) + 120 \\times (16 \\times 5 \\times 5 + 1) + 84 \\times (120 + 1) + 10 \\times (84 + 1) = 61706$$\n",
    "for complete C3 connections.\n",
    "\n",
    "(The number of parameters needed between two layers is $C_{\\mathrm{out}} \\times \\left(C_{\\mathrm{in}} \\times f_1 \\times f_2 + b \\right)$.)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
